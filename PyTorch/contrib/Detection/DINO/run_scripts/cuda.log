/root/miniconda3/envs/wyc_mmlab2/lib/python3.9/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
/root/miniconda3/envs/wyc_mmlab2/lib/python3.9/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
06/23 11:23:50 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 2121947787
    GPU 0: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 12.9, V12.9.86
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.0+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.0+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 2121947787
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

06/23 11:23:52 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16)
backend_args = None
data_root = '/home/01/wyc/datasets/coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 36
model = dict(
    as_two_stage=True,
    backbone=dict(
        depth=50,
        frozen_stages=1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='BN'),
        norm_eval=True,
        num_stages=4,
        out_indices=(
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    bbox_head=dict(
        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),
        loss_cls=dict(
            alpha=0.25,
            gamma=2.0,
            loss_weight=1.0,
            type='FocalLoss',
            use_sigmoid=True),
        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),
        num_classes=80,
        sync_cls_avg_factor=True,
        type='DINOHead'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_size_divisor=1,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='DetDataPreprocessor'),
    decoder=dict(
        layer_cfg=dict(
            cross_attn_cfg=dict(dropout=0.0, embed_dims=256, num_levels=4),
            ffn_cfg=dict(
                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0),
            self_attn_cfg=dict(dropout=0.0, embed_dims=256, num_heads=8)),
        num_layers=6,
        post_norm_cfg=None,
        return_intermediate=True),
    dn_cfg=dict(
        box_noise_scale=1.0,
        group_cfg=dict(dynamic=True, num_dn_queries=100, num_groups=None),
        label_noise_scale=0.5),
    encoder=dict(
        layer_cfg=dict(
            ffn_cfg=dict(
                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0),
            self_attn_cfg=dict(dropout=0.0, embed_dims=256, num_levels=4)),
        num_layers=6),
    neck=dict(
        act_cfg=None,
        in_channels=[
            512,
            1024,
            2048,
        ],
        kernel_size=1,
        norm_cfg=dict(num_groups=32, type='GN'),
        num_outs=4,
        out_channels=256,
        type='ChannelMapper'),
    num_queries=900,
    positional_encoding=dict(
        normalize=True, num_feats=128, offset=0.0, temperature=20),
    test_cfg=dict(max_per_img=300),
    train_cfg=dict(
        assigner=dict(
            match_costs=[
                dict(type='FocalLossCost', weight=2.0),
                dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),
                dict(iou_mode='giou', type='IoUCost', weight=2.0),
            ],
            type='HungarianAssigner')),
    type='DINO',
    with_box_refine=True)
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.1, norm_type=2),
    loss_scale='dynamic',
    optimizer=dict(lr=0.0001, type='AdamW', weight_decay=0.0001),
    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(
        begin=0,
        by_epoch=True,
        end=36,
        gamma=0.1,
        milestones=[
            30,
        ],
        type='MultiStepLR'),
]
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='images/val2017/'),
        data_root='/home/01/wyc/datasets/coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='/home/01/wyc/datasets/coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric='bbox',
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(max_epochs=36, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_train2017.json',
        backend_args=None,
        data_prefix=dict(img='images/train2017/'),
        data_root='/home/01/wyc/datasets/coco/',
        filter_cfg=dict(filter_empty_gt=False, min_size=32),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                transforms=[
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    400,
                                    4200,
                                ),
                                (
                                    500,
                                    4200,
                                ),
                                (
                                    600,
                                    4200,
                                ),
                            ],
                            type='RandomChoiceResize'),
                        dict(
                            allow_negative_crop=True,
                            crop_size=(
                                384,
                                600,
                            ),
                            crop_type='absolute_range',
                            type='RandomCrop'),
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                ],
                type='RandomChoice'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        transforms=[
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            400,
                            4200,
                        ),
                        (
                            500,
                            4200,
                        ),
                        (
                            600,
                            4200,
                        ),
                    ],
                    type='RandomChoiceResize'),
                dict(
                    allow_negative_crop=True,
                    crop_size=(
                        384,
                        600,
                    ),
                    crop_type='absolute_range',
                    type='RandomCrop'),
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
        ],
        type='RandomChoice'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='images/val2017/'),
        data_root='/home/01/wyc/datasets/coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='/home/01/wyc/datasets/coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric='bbox',
    type='CocoMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/dino-4scale_r50_8xb2-36e_coco'

06/23 11:23:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
06/23 11:23:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
loading annotations into memory...
Done (t=15.73s)
creating index...
index created!
06/23 11:24:30 - mmengine - WARNING - backbone.conv1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.conv1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.conv2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.conv3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.downsample.0.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.conv1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.conv2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.conv3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.conv1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.conv2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.conv3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.0001
06/23 11:24:30 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
06/23 11:24:30 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
loading annotations into memory...
Done (t=0.59s)
creating index...
index created!
loading annotations into memory...
Done (t=0.57s)
creating index...
index created!
06/23 11:24:34 - mmengine - INFO - load model from: torchvision://resnet50
06/23 11:24:34 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
06/23 11:24:34 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

06/23 11:24:34 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
06/23 11:24:34 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
06/23 11:24:34 - mmengine - INFO - Checkpoints will be saved to /home/01/wyc/mmdetection/work_dirs/dino-4scale_r50_8xb2-36e_coco.
/root/miniconda3/envs/wyc_mmlab2/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
TCAPPDLL 2025-06-23 11:24:36.309019 - Epoch: 0 Iteration: 0  rank : 0  train.loss : 46.135318756103516  train.ips : 0.5794434872178008 imgs/s train.total_time : 1.7257938385009766 
TCAPPDLL 2025-06-23 11:24:36.723839 - Epoch: 0 Iteration: 1  rank : 0  train.loss : 71.8180923461914  train.ips : 2.4116519078210863 imgs/s train.total_time : 0.4146535396575928 
TCAPPDLL 2025-06-23 11:24:37.112511 - Epoch: 0 Iteration: 2  rank : 0  train.loss : 49.47474670410156  train.ips : 2.5741859895628436 imgs/s train.total_time : 0.388472318649292 
TCAPPDLL 2025-06-23 11:24:37.479552 - Epoch: 0 Iteration: 3  rank : 0  train.loss : 75.0978775024414  train.ips : 2.7257032604040687 imgs/s train.total_time : 0.36687779426574707 
TCAPPDLL 2025-06-23 11:24:37.951790 - Epoch: 0 Iteration: 4  rank : 0  train.loss : 45.112770080566406  train.ips : 2.1181909314263927 imgs/s train.total_time : 0.47210097312927246 
TCAPPDLL 2025-06-23 11:24:38.336832 - Epoch: 0 Iteration: 5  rank : 0  train.loss : 112.47219848632812  train.ips : 2.5979448363859348 imgs/s train.total_time : 0.3849196434020996 
TCAPPDLL 2025-06-23 11:24:38.717891 - Epoch: 0 Iteration: 6  rank : 0  train.loss : 143.6903533935547  train.ips : 2.6251430924748225 imgs/s train.total_time : 0.3809316158294678 
TCAPPDLL 2025-06-23 11:24:39.031190 - Epoch: 0 Iteration: 7  rank : 0  train.loss : 149.2239990234375  train.ips : 3.1931300150737703 imgs/s train.total_time : 0.3131723403930664 
TCAPPDLL 2025-06-23 11:24:39.369205 - Epoch: 0 Iteration: 8  rank : 0  train.loss : 86.7394790649414  train.ips : 2.9595605434640717 imgs/s train.total_time : 0.3378880023956299 
TCAPPDLL 2025-06-23 11:24:39.799752 - Epoch: 0 Iteration: 9  rank : 0  train.loss : 80.4212417602539  train.ips : 2.3233035269667024 imgs/s train.total_time : 0.4304215908050537 
TCAPPDLL 2025-06-23 11:24:40.222736 - Epoch: 0 Iteration: 10  rank : 0  train.loss : 66.48445129394531  train.ips : 2.364862739083882 imgs/s train.total_time : 0.42285752296447754 
TCAPPDLL 2025-06-23 11:24:40.655843 - Epoch: 0 Iteration: 11  rank : 0  train.loss : 86.62529754638672  train.ips : 2.3096247765019045 imgs/s train.total_time : 0.4329707622528076 
TCAPPDLL 2025-06-23 11:24:41.085186 - Epoch: 0 Iteration: 12  rank : 0  train.loss : 59.75107192993164  train.ips : 2.329858241123406 imgs/s train.total_time : 0.4292106628417969 
TCAPPDLL 2025-06-23 11:24:41.499181 - Epoch: 0 Iteration: 13  rank : 0  train.loss : 60.142635345458984  train.ips : 2.4162811209026582 imgs/s train.total_time : 0.41385912895202637 
TCAPPDLL 2025-06-23 11:24:41.898418 - Epoch: 0 Iteration: 14  rank : 0  train.loss : 60.32833480834961  train.ips : 2.505683678272984 imgs/s train.total_time : 0.3990926742553711 
TCAPPDLL 2025-06-23 11:24:42.306436 - Epoch: 0 Iteration: 15  rank : 0  train.loss : 61.075504302978516  train.ips : 2.4516107914493266 imgs/s train.total_time : 0.4078950881958008 
TCAPPDLL 2025-06-23 11:24:42.712795 - Epoch: 0 Iteration: 16  rank : 0  train.loss : 74.76632690429688  train.ips : 2.4617118280377692 imgs/s train.total_time : 0.4062213897705078 
TCAPPDLL 2025-06-23 11:24:43.152943 - Epoch: 0 Iteration: 17  rank : 0  train.loss : 96.69759368896484  train.ips : 2.2726333869752975 imgs/s train.total_time : 0.4400181770324707 
TCAPPDLL 2025-06-23 11:24:43.565316 - Epoch: 0 Iteration: 18  rank : 0  train.loss : 82.68477630615234  train.ips : 2.4259550276500654 imgs/s train.total_time : 0.41220879554748535 
TCAPPDLL 2025-06-23 11:24:44.010120 - Epoch: 0 Iteration: 19  rank : 0  train.loss : 74.14112091064453  train.ips : 2.248967421290505 imgs/s train.total_time : 0.44464850425720215 
TCAPPDLL 2025-06-23 11:24:44.433602 - Epoch: 0 Iteration: 20  rank : 0  train.loss : 92.72938537597656  train.ips : 2.362100551511066 imgs/s train.total_time : 0.4233520030975342 
TCAPPDLL 2025-06-23 11:24:44.853967 - Epoch: 0 Iteration: 21  rank : 0  train.loss : 63.188995361328125  train.ips : 2.3796105868543136 imgs/s train.total_time : 0.42023682594299316 
TCAPPDLL 2025-06-23 11:24:45.264502 - Epoch: 0 Iteration: 22  rank : 0  train.loss : 60.7493896484375  train.ips : 2.4366391920750483 imgs/s train.total_time : 0.4104013442993164 
TCAPPDLL 2025-06-23 11:24:45.645085 - Epoch: 0 Iteration: 23  rank : 0  train.loss : 65.8823471069336  train.ips : 2.6284546884498003 imgs/s train.total_time : 0.38045167922973633 
TCAPPDLL 2025-06-23 11:24:46.114337 - Epoch: 0 Iteration: 24  rank : 0  train.loss : 79.9325180053711  train.ips : 2.1316408836774596 imgs/s train.total_time : 0.46912217140197754 
TCAPPDLL 2025-06-23 11:24:46.586499 - Epoch: 0 Iteration: 25  rank : 0  train.loss : 58.829505920410156  train.ips : 2.118811551080925 imgs/s train.total_time : 0.47196269035339355 
TCAPPDLL 2025-06-23 11:24:46.992324 - Epoch: 0 Iteration: 26  rank : 0  train.loss : 65.55054473876953  train.ips : 2.465066938113908 imgs/s train.total_time : 0.4056684970855713 
TCAPPDLL 2025-06-23 11:24:47.426944 - Epoch: 0 Iteration: 27  rank : 0  train.loss : 57.81616973876953  train.ips : 2.301526392928889 imgs/s train.total_time : 0.4344942569732666 
TCAPPDLL 2025-06-23 11:24:47.841589 - Epoch: 0 Iteration: 28  rank : 0  train.loss : 54.66752624511719  train.ips : 2.412423136187348 imgs/s train.total_time : 0.4145209789276123 
TCAPPDLL 2025-06-23 11:24:48.299488 - Epoch: 0 Iteration: 29  rank : 0  train.loss : 76.54447174072266  train.ips : 2.184451416405218 imgs/s train.total_time : 0.4577808380126953 
TCAPPDLL 2025-06-23 11:24:48.584322 - Epoch: 0 Iteration: 30  rank : 0  train.loss : 76.08865356445312  train.ips : 3.5123585193224334 imgs/s train.total_time : 0.28470897674560547 
TCAPPDLL 2025-06-23 11:24:49.012781 - Epoch: 0 Iteration: 31  rank : 0  train.loss : 63.41856384277344  train.ips : 2.3346878068439136 imgs/s train.total_time : 0.42832279205322266 
TCAPPDLL 2025-06-23 11:24:49.442949 - Epoch: 0 Iteration: 32  rank : 0  train.loss : 54.55611038208008  train.ips : 2.325575876532737 imgs/s train.total_time : 0.43000102043151855 
TCAPPDLL 2025-06-23 11:24:49.885534 - Epoch: 0 Iteration: 33  rank : 0  train.loss : 68.11703491210938  train.ips : 2.260215227594829 imgs/s train.total_time : 0.44243574142456055 
TCAPPDLL 2025-06-23 11:24:50.305864 - Epoch: 0 Iteration: 34  rank : 0  train.loss : 71.90235137939453  train.ips : 2.37981446282164 imgs/s train.total_time : 0.42020082473754883 
TCAPPDLL 2025-06-23 11:24:50.696873 - Epoch: 0 Iteration: 35  rank : 0  train.loss : 67.77928924560547  train.ips : 2.5583416998991133 imgs/s train.total_time : 0.39087820053100586 
TCAPPDLL 2025-06-23 11:24:51.125874 - Epoch: 0 Iteration: 36  rank : 0  train.loss : 58.85185623168945  train.ips : 2.3317220748709837 imgs/s train.total_time : 0.4288675785064697 
TCAPPDLL 2025-06-23 11:24:51.549527 - Epoch: 0 Iteration: 37  rank : 0  train.loss : 63.61805725097656  train.ips : 2.3611750526215642 imgs/s train.total_time : 0.42351794242858887 
TCAPPDLL 2025-06-23 11:24:51.963682 - Epoch: 0 Iteration: 38  rank : 0  train.loss : 63.77104949951172  train.ips : 2.4153126866131465 imgs/s train.total_time : 0.41402506828308105 
TCAPPDLL 2025-06-23 11:24:52.395423 - Epoch: 0 Iteration: 39  rank : 0  train.loss : 72.96688079833984  train.ips : 2.316899490639443 imgs/s train.total_time : 0.4316112995147705 
TCAPPDLL 2025-06-23 11:24:52.810557 - Epoch: 0 Iteration: 40  rank : 0  train.loss : 59.564903259277344  train.ips : 2.410059689760345 imgs/s train.total_time : 0.41492748260498047 
TCAPPDLL 2025-06-23 11:24:53.257827 - Epoch: 0 Iteration: 41  rank : 0  train.loss : 63.213748931884766  train.ips : 2.236727127869765 imgs/s train.total_time : 0.4470818042755127 
TCAPPDLL 2025-06-23 11:24:53.651332 - Epoch: 0 Iteration: 42  rank : 0  train.loss : 79.55634307861328  train.ips : 2.542176524816548 imgs/s train.total_time : 0.39336371421813965 
TCAPPDLL 2025-06-23 11:24:54.056806 - Epoch: 0 Iteration: 43  rank : 0  train.loss : 62.75973892211914  train.ips : 2.467059148073404 imgs/s train.total_time : 0.40534090995788574 
TCAPPDLL 2025-06-23 11:24:54.503753 - Epoch: 0 Iteration: 44  rank : 0  train.loss : 63.74469757080078  train.ips : 2.238026837300732 imgs/s train.total_time : 0.4468221664428711 
TCAPPDLL 2025-06-23 11:24:54.761516 - Epoch: 0 Iteration: 45  rank : 0  train.loss : 68.31559753417969  train.ips : 3.881411754254298 imgs/s train.total_time : 0.25763821601867676 
TCAPPDLL 2025-06-23 11:24:55.108799 - Epoch: 0 Iteration: 46  rank : 0  train.loss : 88.69212341308594  train.ips : 2.8804599611433925 imgs/s train.total_time : 0.3471667766571045 
TCAPPDLL 2025-06-23 11:24:55.365986 - Epoch: 0 Iteration: 47  rank : 0  train.loss : 89.22945404052734  train.ips : 3.8899684299170127 imgs/s train.total_time : 0.25707149505615234 
TCAPPDLL 2025-06-23 11:24:55.794709 - Epoch: 0 Iteration: 48  rank : 0  train.loss : 103.71125793457031  train.ips : 2.333182583058673 imgs/s train.total_time : 0.42859911918640137 
TCAPPDLL 2025-06-23 11:24:56.266885 - Epoch: 0 Iteration: 49  rank : 0  train.loss : 91.41898345947266  train.ips : 2.118400617392758 imgs/s train.total_time : 0.47205424308776855 
06/23 11:24:56 - mmengine - INFO - Epoch(train)  [1][    50/118287]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 21 days, 8:47:45  time: 0.4335  data_time: 0.0156  memory: 3099  grad_norm: nan  loss: 73.8010  loss_cls: 1.5655  loss_bbox: 2.9911  loss_iou: 2.3241  d0.loss_cls: 1.0892  d0.loss_bbox: 3.0790  d0.loss_iou: 2.3603  d1.loss_cls: 1.4509  d1.loss_bbox: 3.0321  d1.loss_iou: 2.3399  d2.loss_cls: 2.6819  d2.loss_bbox: 3.0119  d2.loss_iou: 2.3356  d3.loss_cls: 2.4249  d3.loss_bbox: 3.0057  d3.loss_iou: 2.3295  d4.loss_cls: 3.0906  d4.loss_bbox: 2.9972  d4.loss_iou: 2.3281  enc_loss_cls: 1.1889  enc_loss_bbox: 3.0610  enc_loss_iou: 2.3495  dn_loss_cls: 1.0577  dn_loss_bbox: 1.4200  dn_loss_iou: 1.3240  d0.dn_loss_cls: 1.0354  d0.dn_loss_bbox: 1.4044  d0.dn_loss_iou: 1.2942  d1.dn_loss_cls: 1.0595  d1.dn_loss_bbox: 1.4051  d1.dn_loss_iou: 1.3019  d2.dn_loss_cls: 1.1084  d2.dn_loss_bbox: 1.4076  d2.dn_loss_iou: 1.3074  d3.dn_loss_cls: 1.1016  d3.dn_loss_bbox: 1.4105  d3.dn_loss_iou: 1.3122  d4.dn_loss_cls: 1.0815  d4.dn_loss_bbox: 1.4147  d4.dn_loss_iou: 1.3182
TCAPPDLL 2025-06-23 11:24:56.718753 - Epoch: 0 Iteration: 50  rank : 0  train.loss : 69.0395278930664  train.ips : 2.213875251840408 imgs/s train.total_time : 0.45169663429260254 
TCAPPDLL 2025-06-23 11:24:57.106214 - Epoch: 0 Iteration: 51  rank : 0  train.loss : 71.11605072021484  train.ips : 2.5818712100366814 imgs/s train.total_time : 0.3873159885406494 
TCAPPDLL 2025-06-23 11:24:57.520147 - Epoch: 0 Iteration: 52  rank : 0  train.loss : 91.71963500976562  train.ips : 2.41664448400832 imgs/s train.total_time : 0.41379690170288086 
TCAPPDLL 2025-06-23 11:24:57.944126 - Epoch: 0 Iteration: 53  rank : 0  train.loss : 79.81919860839844  train.ips : 2.359319593195932 imgs/s train.total_time : 0.42385101318359375 
TCAPPDLL 2025-06-23 11:24:58.410946 - Epoch: 0 Iteration: 54  rank : 0  train.loss : 57.37498474121094  train.ips : 2.142744240578918 imgs/s train.total_time : 0.466691255569458 
TCAPPDLL 2025-06-23 11:24:58.810046 - Epoch: 0 Iteration: 55  rank : 0  train.loss : 54.1932487487793  train.ips : 2.506441338345056 imgs/s train.total_time : 0.3989720344543457 
TCAPPDLL 2025-06-23 11:24:59.054026 - Epoch: 0 Iteration: 56  rank : 0  train.loss : 62.9987678527832  train.ips : 4.100825678655058 imgs/s train.total_time : 0.24385333061218262 
TCAPPDLL 2025-06-23 11:24:59.349169 - Epoch: 0 Iteration: 57  rank : 0  train.loss : 80.83179473876953  train.ips : 3.3896159521835334 imgs/s train.total_time : 0.29501867294311523 
TCAPPDLL 2025-06-23 11:24:59.759635 - Epoch: 0 Iteration: 58  rank : 0  train.loss : 66.27989959716797  train.ips : 2.4370214481853814 imgs/s train.total_time : 0.410336971282959 
TCAPPDLL 2025-06-23 11:25:00.183258 - Epoch: 0 Iteration: 59  rank : 0  train.loss : 67.15444946289062  train.ips : 2.3618398491325063 imgs/s train.total_time : 0.4233987331390381 
TCAPPDLL 2025-06-23 11:25:00.628748 - Epoch: 0 Iteration: 60  rank : 0  train.loss : 59.269561767578125  train.ips : 2.245634474254976 imgs/s train.total_time : 0.4453084468841553 
TCAPPDLL 2025-06-23 11:25:01.094358 - Epoch: 0 Iteration: 61  rank : 0  train.loss : 57.6557731628418  train.ips : 2.148349312465362 imgs/s train.total_time : 0.46547365188598633 
TCAPPDLL 2025-06-23 11:25:01.521425 - Epoch: 0 Iteration: 62  rank : 0  train.loss : 78.11651611328125  train.ips : 2.342329482787025 imgs/s train.total_time : 0.4269254207611084 
TCAPPDLL 2025-06-23 11:25:01.960158 - Epoch: 0 Iteration: 63  rank : 0  train.loss : 46.06946563720703  train.ips : 2.279962840495163 imgs/s train.total_time : 0.43860363960266113 
TCAPPDLL 2025-06-23 11:25:02.397126 - Epoch: 0 Iteration: 64  rank : 0  train.loss : 68.78385162353516  train.ips : 2.289132375831483 imgs/s train.total_time : 0.4368467330932617 
TCAPPDLL 2025-06-23 11:25:02.817808 - Epoch: 0 Iteration: 65  rank : 0  train.loss : 51.12778091430664  train.ips : 2.3777799698178756 imgs/s train.total_time : 0.420560359954834 
TCAPPDLL 2025-06-23 11:25:03.240657 - Epoch: 0 Iteration: 66  rank : 0  train.loss : 59.14986038208008  train.ips : 2.365608330127905 imgs/s train.total_time : 0.42272424697875977 
TCAPPDLL 2025-06-23 11:25:03.644806 - Epoch: 0 Iteration: 67  rank : 0  train.loss : 62.014984130859375  train.ips : 2.4750953468157437 imgs/s train.total_time : 0.4040248394012451 
TCAPPDLL 2025-06-23 11:25:04.050536 - Epoch: 0 Iteration: 68  rank : 0  train.loss : 73.05753326416016  train.ips : 2.4656422314972666 imgs/s train.total_time : 0.40557384490966797 
TCAPPDLL 2025-06-23 11:25:04.458326 - Epoch: 0 Iteration: 69  rank : 0  train.loss : 60.13693618774414  train.ips : 2.45308622552136 imgs/s train.total_time : 0.4076497554779053 
TCAPPDLL 2025-06-23 11:25:04.934109 - Epoch: 0 Iteration: 70  rank : 0  train.loss : 76.5606689453125  train.ips : 2.1023237163422017 imgs/s train.total_time : 0.4756641387939453 
TCAPPDLL 2025-06-23 11:25:05.358831 - Epoch: 0 Iteration: 71  rank : 0  train.loss : 68.940673828125  train.ips : 2.355142558900968 imgs/s train.total_time : 0.424602746963501 
TCAPPDLL 2025-06-23 11:25:05.642931 - Epoch: 0 Iteration: 72  rank : 0  train.loss : 63.941036224365234  train.ips : 3.5213317292313997 imgs/s train.total_time : 0.2839834690093994 
TCAPPDLL 2025-06-23 11:25:06.056792 - Epoch: 0 Iteration: 73  rank : 0  train.loss : 49.750003814697266  train.ips : 2.4169745291015716 imgs/s train.total_time : 0.4137403964996338 
TCAPPDLL 2025-06-23 11:25:06.483951 - Epoch: 0 Iteration: 74  rank : 0  train.loss : 50.26958084106445  train.ips : 2.341692618452362 imgs/s train.total_time : 0.42704153060913086 
TCAPPDLL 2025-06-23 11:25:06.944433 - Epoch: 0 Iteration: 75  rank : 0  train.loss : 82.7620620727539  train.ips : 2.1721959392098524 imgs/s train.total_time : 0.46036362648010254 
TCAPPDLL 2025-06-23 11:25:07.368074 - Epoch: 0 Iteration: 76  rank : 0  train.loss : 48.87973403930664  train.ips : 2.361159102104004 imgs/s train.total_time : 0.4235208034515381 
TCAPPDLL 2025-06-23 11:25:07.807717 - Epoch: 0 Iteration: 77  rank : 0  train.loss : 49.92912292480469  train.ips : 2.2752123974357166 imgs/s train.total_time : 0.43951940536499023 
TCAPPDLL 2025-06-23 11:25:08.213760 - Epoch: 0 Iteration: 78  rank : 0  train.loss : 51.58005905151367  train.ips : 2.463600213801975 imgs/s train.total_time : 0.40591001510620117 
TCAPPDLL 2025-06-23 11:25:08.682771 - Epoch: 0 Iteration: 79  rank : 0  train.loss : 51.82788848876953  train.ips : 2.132731289741106 imgs/s train.total_time : 0.46888232231140137 
TCAPPDLL 2025-06-23 11:25:09.140460 - Epoch: 0 Iteration: 80  rank : 0  train.loss : 55.15480422973633  train.ips : 2.185502011568669 imgs/s train.total_time : 0.45756077766418457 
TCAPPDLL 2025-06-23 11:25:09.589416 - Epoch: 0 Iteration: 81  rank : 0  train.loss : 49.169925689697266  train.ips : 2.228418081287267 imgs/s train.total_time : 0.4487488269805908 
TCAPPDLL 2025-06-23 11:25:10.008711 - Epoch: 0 Iteration: 82  rank : 0  train.loss : 56.913387298583984  train.ips : 2.3857610987584588 imgs/s train.total_time : 0.41915345191955566 
TCAPPDLL 2025-06-23 11:25:10.447137 - Epoch: 0 Iteration: 83  rank : 0  train.loss : 56.73443603515625  train.ips : 2.2815664532862185 imgs/s train.total_time : 0.4382953643798828 
TCAPPDLL 2025-06-23 11:25:10.722172 - Epoch: 0 Iteration: 84  rank : 0  train.loss : 45.7197265625  train.ips : 3.637526071817287 imgs/s train.total_time : 0.27491211891174316 
TCAPPDLL 2025-06-23 11:25:10.994869 - Epoch: 0 Iteration: 85  rank : 0  train.loss : 57.22559356689453  train.ips : 3.668652178552623 imgs/s train.total_time : 0.2725796699523926 
TCAPPDLL 2025-06-23 11:25:11.424395 - Epoch: 0 Iteration: 86  rank : 0  train.loss : 56.937374114990234  train.ips : 2.328881534929303 imgs/s train.total_time : 0.42939066886901855 
TCAPPDLL 2025-06-23 11:25:11.680665 - Epoch: 0 Iteration: 87  rank : 0  train.loss : 48.6163215637207  train.ips : 3.904209520032989 imgs/s train.total_time : 0.2561337947845459 
TCAPPDLL 2025-06-23 11:25:11.998283 - Epoch: 0 Iteration: 88  rank : 0  train.loss : 50.66654586791992  train.ips : 3.1498984655684126 imgs/s train.total_time : 0.3174705505371094 
TCAPPDLL 2025-06-23 11:25:12.410729 - Epoch: 0 Iteration: 89  rank : 0  train.loss : 46.332420349121094  train.ips : 2.425308345717276 imgs/s train.total_time : 0.41231870651245117 
TCAPPDLL 2025-06-23 11:25:12.849347 - Epoch: 0 Iteration: 90  rank : 0  train.loss : 72.21183013916016  train.ips : 2.2805293663480466 imgs/s train.total_time : 0.4384946823120117 
TCAPPDLL 2025-06-23 11:25:13.286086 - Epoch: 0 Iteration: 91  rank : 0  train.loss : 55.00959014892578  train.ips : 2.290357387805741 imgs/s train.total_time : 0.4366130828857422 
TCAPPDLL 2025-06-23 11:25:13.623851 - Epoch: 0 Iteration: 92  rank : 0  train.loss : 61.56244659423828  train.ips : 2.9617967213577803 imgs/s train.total_time : 0.3376328945159912 
TCAPPDLL 2025-06-23 11:25:14.048789 - Epoch: 0 Iteration: 93  rank : 0  train.loss : 49.110042572021484  train.ips : 2.3540058133106743 imgs/s train.total_time : 0.4248077869415283 
TCAPPDLL 2025-06-23 11:25:14.497911 - Epoch: 0 Iteration: 94  rank : 0  train.loss : 60.466670989990234  train.ips : 2.2271602525843592 imgs/s train.total_time : 0.4490022659301758 
TCAPPDLL 2025-06-23 11:25:14.921299 - Epoch: 0 Iteration: 95  rank : 0  train.loss : 55.13251495361328  train.ips : 2.3625928506610445 imgs/s train.total_time : 0.4232637882232666 
TCAPPDLL 2025-06-23 11:25:15.358951 - Epoch: 0 Iteration: 96  rank : 0  train.loss : 60.40653610229492  train.ips : 2.2855548580595664 imgs/s train.total_time : 0.437530517578125 
TCAPPDLL 2025-06-23 11:25:15.613015 - Epoch: 0 Iteration: 97  rank : 0  train.loss : 54.80857467651367  train.ips : 3.93792906608181 imgs/s train.total_time : 0.2539405822753906 
TCAPPDLL 2025-06-23 11:25:16.061845 - Epoch: 0 Iteration: 98  rank : 0  train.loss : 52.26919174194336  train.ips : 2.2286181868417976 imgs/s train.total_time : 0.44870853424072266 
TCAPPDLL 2025-06-23 11:25:16.557317 - Epoch: 0 Iteration: 99  rank : 0  train.loss : 62.675411224365234  train.ips : 2.0187867364639427 imgs/s train.total_time : 0.4953470230102539 
06/23 11:25:16 - mmengine - INFO - Epoch(train)  [1][   100/118287]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 20 days, 16:18:43  time: 0.4057  data_time: 0.0062  memory: 3142  grad_norm: 65.7022  loss: 60.3495  loss_cls: 1.1456  loss_bbox: 2.3960  loss_iou: 1.9096  d0.loss_cls: 1.0552  d0.loss_bbox: 2.4135  d0.loss_iou: 1.9622  d1.loss_cls: 1.1259  d1.loss_bbox: 2.3821  d1.loss_iou: 1.9342  d2.loss_cls: 1.1452  d2.loss_bbox: 2.3746  d2.loss_iou: 1.9246  d3.loss_cls: 1.1447  d3.loss_bbox: 2.3756  d3.loss_iou: 1.9227  d4.loss_cls: 1.1434  d4.loss_bbox: 2.3835  d4.loss_iou: 1.9170  enc_loss_cls: 1.0946  enc_loss_bbox: 2.3932  enc_loss_iou: 1.9551  dn_loss_cls: 0.9670  dn_loss_bbox: 1.5087  dn_loss_iou: 1.2881  d0.dn_loss_cls: 0.8435  d0.dn_loss_bbox: 1.4737  d0.dn_loss_iou: 1.2804  d1.dn_loss_cls: 0.8857  d1.dn_loss_bbox: 1.4831  d1.dn_loss_iou: 1.2831  d2.dn_loss_cls: 0.9661  d2.dn_loss_bbox: 1.4919  d2.dn_loss_iou: 1.2844  d3.dn_loss_cls: 0.9665  d3.dn_loss_bbox: 1.4981  d3.dn_loss_iou: 1.2841  d4.dn_loss_cls: 0.9569  d4.dn_loss_bbox: 1.5036  d4.dn_loss_iou: 1.2862
